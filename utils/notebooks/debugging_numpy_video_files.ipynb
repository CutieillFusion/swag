{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "chunk_tensor = torch.from_numpy(chunk_array).float()\n",
    "chunk_tensor = F.interpolate(\n",
    "    chunk_tensor,\n",
    "    size=(64, 60),\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,\n",
    ")\n",
    "frame = chunk_tensor[600].permute(1, 2, 0)\n",
    "frame = (frame * 255).byte().numpy()\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_2.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "frame = chunk_array[600].transpose(1, 2, 0)  # CHW -> HWC\n",
    "frame = cv2.resize(frame, (60, 64), interpolation=cv2.INTER_AREA)\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_1.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3.104] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "frame = chunk_array[600]  # Keep as CHW\n",
    "frame = F.interpolate(torch.from_numpy(frame).float().unsqueeze(0), size=(64, 60), mode='area')[0].numpy()\n",
    "frame = frame.transpose(1, 2, 0)  # Convert to HWC at the end for cv2\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_1.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "frame = F.interpolate(torch.from_numpy(chunk_array).float(), size=(64, 60), mode='area')[600].numpy()\n",
    "frame = frame.transpose(1, 2, 0)  # Convert to HWC at the end for cv2\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_1.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3, 64, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "chunk_tensor = torch.from_numpy(chunk_array).float()\n",
    "frame = F.interpolate(chunk_tensor, size=(64, 60), mode='area')\n",
    "print(frame.shape)\n",
    "frame = frame.numpy()[600]\n",
    "frame = frame.transpose(1, 2, 0)  # Single transpose at end for HWC\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_0.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "frame = chunk_array[600].transpose(1, 2, 0)  # CHW -> HWC\n",
    "frame = cv2.resize(frame, (60, 64), interpolation=cv2.INTER_LINEAR)\n",
    "frame = (frame * 255).astype(np.uint8)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_3.png\", frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FPS: 60.0\n",
      "Frame skip interval: 2\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Got 4D input, but linear mode needs 3D input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_frames\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m frames to output video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m frame_idx == \u001b[32m1624\u001b[39m * \u001b[32m2\u001b[39m:\n\u001b[32m     52\u001b[39m     frame_resized = torch.from_numpy(frame_resized).permute(\u001b[32m2\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m).unsqueeze(\u001b[32m0\u001b[39m).float()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     frame_resized = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_resized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlinear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     frame_resized = frame_resized.squeeze(\u001b[32m0\u001b[39m).permute(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m,\u001b[32m0\u001b[39m).numpy()\n\u001b[32m     55\u001b[39m     cv2.imwrite(os.path.join(args[\u001b[33m'\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m'\u001b[39m], \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m), frame_resized)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/ai_club/nes_2025/swag/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4716\u001b[39m, in \u001b[36minterpolate\u001b[39m\u001b[34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[39m\n\u001b[32m   4714\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGot 3D input, but trilinear mode needs 5D input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4715\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4716\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGot 4D input, but linear mode needs 3D input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4717\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mtrilinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   4718\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGot 4D input, but trilinear mode needs 5D input\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Got 4D input, but linear mode needs 3D input"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = {\n",
    "        \"input_dir\": \"/data/ai_club/nes_2025/swag/idm/data/raw\",\n",
    "        \"output_dir\": \"/data/ai_club/nes_2025/swag/idm/data/formatted\",\n",
    "        \"width\": 256,\n",
    "        \"height\": 240,\n",
    "        \"labels\": True,\n",
    "        \"video_id\": \"4814603\",\n",
    "    }\n",
    "\n",
    "    video_filepath = os.path.join(args['input_dir'], f\"video_{args['video_id']}.mp4\")\n",
    "    if not os.path.exists(video_filepath):\n",
    "        print(f\"Video file {video_filepath} does not exist.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_filepath)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open video.\")\n",
    "        return\n",
    "\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Original FPS: {original_fps}\")\n",
    "    frame_skip_interval = max(1, int(original_fps / 30))\n",
    "    print(f\"Frame skip interval: {frame_skip_interval}\")\n",
    "\n",
    "    output_video_path = os.path.join(args['output_dir'], f\"video_{args['video_id']}.mp4\")\n",
    "    os.makedirs(args['output_dir'], exist_ok=True)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(\n",
    "        output_video_path, fourcc, 30, (args['width'], args['height'])\n",
    "    )\n",
    "\n",
    "    frame_idx = 0\n",
    "    saved_frames = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % frame_skip_interval == 0:\n",
    "            frame_resized = cv2.resize(frame, (args['width'], args['height']))\n",
    "            video_writer.write(frame_resized)\n",
    "            saved_frames += 1\n",
    "        if frame_idx == 1624 * 2:\n",
    "            frame_resized = torch.from_numpy(frame_resized).permute(2,0,1).unsqueeze(0).float()\n",
    "            frame_resized = F.interpolate(frame_resized, size=(60, 64), mode='linear', align_corners=True)\n",
    "            frame_resized = frame_resized.squeeze(0).permute(1,2,0).numpy()\n",
    "            cv2.imwrite(os.path.join(args['output_dir'], f\"frame_{frame_idx}.png\"), frame_resized)\n",
    "            cap.release()\n",
    "            return\n",
    "        frame_idx += 1\n",
    "\n",
    "    video_writer.release()\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    if args['labels']:\n",
    "        with open(os.path.join(args['input_dir'], f\"labels_{args['video_id']}.txt\"), \"r\") as f:\n",
    "            labels = f.readlines()\n",
    "\n",
    "        sampled_labels = labels[::frame_skip_interval]\n",
    "\n",
    "        with open(os.path.join(args['output_dir'], f\"labels_{args['video_id']}.txt\"), \"w\") as f:\n",
    "            f.writelines(sampled_labels)\n",
    "\n",
    "    print(f\"Saved {saved_frames} frames to output video: {output_video_path}\")\n",
    "    print(f\"Processing completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the numpy file containing frame 1642\n",
    "start_frame = 1024  # Based on sequence length from convert_to_numpy_2.py\n",
    "end_frame = 2048\n",
    "numpy_path = os.path.join(\"/data/ai_club/nes_2025/swag/idm/data/testing\", f\"{'4814603'}/frames_{start_frame}_{end_frame}.npy\")\n",
    "\n",
    "# Load the numpy array\n",
    "video_data = np.load(numpy_path)\n",
    "\n",
    "# Get frame 1642 (adjusting for sequence offset)\n",
    "frame_idx = 1642 - start_frame\n",
    "frame = video_data[frame_idx]\n",
    "\n",
    "# Convert from TCHW to HWC format\n",
    "frame = frame.transpose(1, 2, 0)\n",
    "\n",
    "# Save the frame\n",
    "output_path = os.path.join('/data/ai_club/nes_2025/swag/idm/data/testing', f\"frame_1642_from_numpy.png\") \n",
    "cv2.imwrite(output_path, frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:843: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m chunk_tensor = torch.from_numpy(chunk_array).float()\n\u001b[32m      5\u001b[39m chunk_tensor = F.interpolate(\n\u001b[32m      6\u001b[39m     chunk_tensor.permute(\u001b[32m0\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m),\n\u001b[32m      7\u001b[39m     size=(\u001b[32m64\u001b[39m, \u001b[32m60\u001b[39m),\n\u001b[32m      8\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33marea\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m ).permute(\u001b[32m0\u001b[39m,\u001b[32m2\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/data/ai_club/nes_2025/swag/frame_0.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:843: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'imwrite_'\n"
     ]
    }
   ],
   "source": [
    "chunk_path = \"/data/ai_club/nes_2025/swag/idm/data/numpy/4814603/frames_1024_2048.npy\"\n",
    "\n",
    "chunk_array = np.load(chunk_path, mmap_mode=\"r+\")\n",
    "chunk_tensor = torch.from_numpy(chunk_array).float()\n",
    "chunk_tensor = F.interpolate(\n",
    "    chunk_tensor.permute(0,3,1,2),\n",
    "    size=(64, 60),\n",
    "    mode=\"area\"\n",
    ").permute(0,2,3,1)\n",
    "cv2.imwrite(\"/data/ai_club/nes_2025/swag/frame_0.png\", chunk_tensor[600].numpy())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
